{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/rezafayaz/Documents/Dissertation MDS /Final Files/BigOilNLPAnalysis/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n",
            "/Users/rezafayaz/Documents/Dissertation MDS /Final Files/BigOilNLPAnalysis/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "# In notebooks/Colab, install BEFORE importing fitz on a fresh runtime:\n",
        "# !pip install PyMuPDF\n",
        "import spacy\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IllK3qv-KFw8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“„ Processing: SHELL_CSR_2022.pdf\n",
            "ðŸ“„ Processing: TOTAL_CSR_2022.pdf\n",
            "ðŸ“„ Processing: TOTAL_CSR_2023.pdf\n",
            "ðŸ“„ Processing: SHELL_CSR_2023.pdf\n",
            "ðŸ“„ Processing: BP_CSR_2017.pdf\n",
            "ðŸ“„ Processing: SHELL_CSR_2021.pdf\n",
            "ðŸ“„ Processing: TOTAL_CSR_2021.pdf\n",
            "ðŸ“„ Processing: CHEVRON_CSR_2017.pdf\n",
            "ðŸ“„ Processing: TOTAL_CSR_2020.pdf\n",
            "ðŸ“„ Processing: SHELL_CSR_2020.pdf\n",
            "ðŸ“„ Processing: SHELL_CSR_2018.pdf\n",
            "ðŸ“„ Processing: TOTAL_CSR_2024.pdf\n",
            "ðŸ“„ Processing: TOTAL_CSR_2018.pdf\n",
            "ðŸ“„ Processing: TOTAL_CSR_2019.pdf\n",
            "ðŸ“„ Processing: SHELL_CSR_2019.pdf\n",
            "ðŸ“„ Processing: EXXON_CSR_2018.pdf\n",
            "ðŸ“„ Processing: EXXON_CSR_2024.pdf\n",
            "ðŸ“„ Processing: EXXON_CSR_2019.pdf\n",
            "ðŸ“„ Processing: EXXON_CSR_2022.pdf\n",
            "ðŸ“„ Processing: EXXON_CSR_2023.pdf\n",
            "ðŸ“„ Processing: EXXON_CSR_2017.pdf\n",
            "ðŸ“„ Processing: BP_CSR_2021.pdf\n",
            "ðŸ“„ Processing: SHELL_CSR_2017.pdf\n",
            "ðŸ“„ Processing: TOTAL_CSR_2017.pdf\n",
            "ðŸ“„ Processing: CHEVRON_CSR_2021.pdf\n",
            "ðŸ“„ Processing: CHEVRON_CSR_2020.pdf\n",
            "ðŸ“„ Processing: BP_CSR_2020.pdf\n",
            "ðŸ“„ Processing: BP_CSR_2022.pdf\n",
            "ðŸ“„ Processing: CHEVRON_CSR_2022.pdf\n",
            "ðŸ“„ Processing: CHEVRON_CSR_2023.pdf\n",
            "ðŸ“„ Processing: BP_CSR_2023.pdf\n",
            "ðŸ“„ Processing: BP_CSR_2018.pdf\n",
            "ðŸ“„ Processing: BP_CSR_2024.pdf\n",
            "ðŸ“„ Processing: CHEVRON_CSR_2018.pdf\n",
            "ðŸ“„ Processing: CHEVRON_CSR_2024.pdf\n",
            "ðŸ“„ Processing: CHEVRON_CSR_2019.pdf\n",
            "ðŸ“„ Processing: BP_CSR_2019.pdf\n",
            "âœ… Extracted 4849 pages from 5 companies\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Year</th>\n",
              "      <th>Page</th>\n",
              "      <th>Text</th>\n",
              "      <th>Char_Count</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Is_Sparse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SHELL</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>Responsible \\nenergy\\n#PoweringProgress\\nShell...</td>\n",
              "      <td>76</td>\n",
              "      <td>8</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SHELL</td>\n",
              "      <td>2022</td>\n",
              "      <td>2</td>\n",
              "      <td>Contents\\nRead the Shell Sustainability Report...</td>\n",
              "      <td>1876</td>\n",
              "      <td>271</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SHELL</td>\n",
              "      <td>2022</td>\n",
              "      <td>3</td>\n",
              "      <td>Sustainability at Shell\\nWelcome to the Shell ...</td>\n",
              "      <td>510</td>\n",
              "      <td>74</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SHELL</td>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>Letter from the CEO\\nWael Sawan\\nChief Executi...</td>\n",
              "      <td>4180</td>\n",
              "      <td>669</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SHELL</td>\n",
              "      <td>2022</td>\n",
              "      <td>5</td>\n",
              "      <td>Respecting nature\\nPowering Progress is also a...</td>\n",
              "      <td>3349</td>\n",
              "      <td>531</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Company  Year  Page                                               Text  \\\n",
              "0   SHELL  2022     1  Responsible \\nenergy\\n#PoweringProgress\\nShell...   \n",
              "1   SHELL  2022     2  Contents\\nRead the Shell Sustainability Report...   \n",
              "2   SHELL  2022     3  Sustainability at Shell\\nWelcome to the Shell ...   \n",
              "3   SHELL  2022     4  Letter from the CEO\\nWael Sawan\\nChief Executi...   \n",
              "4   SHELL  2022     5  Respecting nature\\nPowering Progress is also a...   \n",
              "\n",
              "   Char_Count  Word_Count  Is_Sparse  \n",
              "0          76           8      False  \n",
              "1        1876         271      False  \n",
              "2         510          74      False  \n",
              "3        4180         669      False  \n",
              "4        3349         531      False  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# data extraction\n",
        "\n",
        "def filename_creator(sus_report):\n",
        "    \"\"\"Extract company name and year from filename\"\"\"\n",
        "    name = os.path.splitext(os.path.basename(sus_report))[0]\n",
        "    parts = re.split(r\"[_\\-\\s]\", name)\n",
        "    year = next((p for p in parts if re.fullmatch(r\"\\d{4}\", p)), \"Unknown\")\n",
        "    companies = {\"BP\", \"TOTAL\", \"SHELL\",\"EXXON\",\"CHEVRON\"}  # extend later\n",
        "    company = next((p.upper() for p in parts if p.upper() in companies), \"Unknown\")\n",
        "    return company, year\n",
        "\n",
        "def extract_pages_fitz(file_path, sparse_threshold=50):\n",
        "    \"\"\"\n",
        "    Extract text from PDF using PyMuPDF with proper page numbers.\n",
        "    Keeps ALL pages (including short ones), and flags sparse pages.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "\n",
        "    try:\n",
        "        doc = fitz.open(file_path)\n",
        "\n",
        "        for page_num in range(len(doc)):\n",
        "            page = doc[page_num]\n",
        "            text = page.get_text(\"text\").strip()  # Extract + trim\n",
        "\n",
        "            char_count = len(text)\n",
        "            word_count = len(text.split()) if text else 0\n",
        "\n",
        "            data.append({\n",
        "                \"page_number\": page_num + 1,  # 1-indexed\n",
        "                \"text\": text,\n",
        "                \"char_count\": char_count,\n",
        "                \"word_count\": word_count,\n",
        "                \"is_sparse\": char_count < sparse_threshold\n",
        "            })\n",
        "\n",
        "        doc.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "def process_all_pdfs(folder_path, sparse_threshold=50):\n",
        "    \"\"\"Process all PDFs in folder and create dataset\"\"\"\n",
        "    all_data = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith(\".pdf\"):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            print(f\"ðŸ“„ Processing: {filename}\")\n",
        "\n",
        "            company, year = filename_creator(filename)\n",
        "            pages_data = extract_pages_fitz(file_path, sparse_threshold=sparse_threshold)\n",
        "\n",
        "            for page_info in pages_data:\n",
        "                all_data.append({\n",
        "                    \"Company\": company,\n",
        "                    \"Year\": year,\n",
        "                    \"Page\": page_info[\"page_number\"],\n",
        "                    \"Text\": page_info[\"text\"],\n",
        "                    \"Char_Count\": page_info[\"char_count\"],\n",
        "                    \"Word_Count\": page_info[\"word_count\"],\n",
        "                    \"Is_Sparse\": page_info[\"is_sparse\"],\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(all_data)\n",
        "\n",
        "# Usage\n",
        "folder_path = \"content/\"\n",
        "df = process_all_pdfs(folder_path, sparse_threshold=50)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"Datasets/BIGOIL_Original_Dataset.csv\", index=False)\n",
        "print(f\"âœ… Extracted {len(df)} pages from {df['Company'].nunique()} companies\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEJNLRxBKNTl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/rezafayaz/Documents/Dissertation MDS /Final Files/BigOilNLPAnalysis/.venv/lib/python3.9/site-packages/spacy/pipeline/lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original rows: 4849\n",
            "New rows after chunking: 9038\n",
            "âœ… Saved: BIGOIL_pages_sentence_chunked.csv\n"
          ]
        }
      ],
      "source": [
        "# chunking the writing blocks\n",
        "\n",
        "df = pd.read_csv(\"Datasets/BIGOIL_Original_Dataset.csv\")\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"tagger\"])\n",
        "\n",
        "def split_long_text(\n",
        "    text,\n",
        "    target_words=400,\n",
        "    max_words=450\n",
        "):\n",
        "    \"\"\"\n",
        "    Split text into sentence-based chunks.\n",
        "    Sentences are accumulated until ~target_words.\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
        "\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_word_count = 0\n",
        "\n",
        "    for sent in sentences:\n",
        "        sent_word_count = len(sent.split())\n",
        "\n",
        "        if current_word_count + sent_word_count <= target_words:\n",
        "            current_chunk.append(sent)\n",
        "            current_word_count += sent_word_count\n",
        "        else:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            current_chunk = [sent]\n",
        "            current_word_count = sent_word_count\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "new_rows = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    text = str(row[\"Text\"])\n",
        "    word_count = row[\"Word_Count\"]\n",
        "\n",
        "    # Case 1: short rows â†’ keep as-is\n",
        "    if word_count <= 450:\n",
        "        new_row = row.to_dict()\n",
        "        new_row[\"Subpage\"] = float(row[\"Page\"])  # e.g. 40.0\n",
        "        new_rows.append(new_row)\n",
        "        continue\n",
        "\n",
        "    # Case 2: long rows â†’ split\n",
        "    chunks = split_long_text(text)\n",
        "\n",
        "    for i, chunk in enumerate(chunks, start=1):\n",
        "        new_row = row.to_dict()\n",
        "        new_row[\"Text\"] = chunk\n",
        "        new_row[\"Word_Count\"] = len(chunk.split())\n",
        "        new_row[\"Char_Count\"] = len(chunk)\n",
        "        new_row[\"Subpage\"] = float(f\"{int(row['Page'])}.{i}\")  # 40.1, 40.2, ...\n",
        "        new_rows.append(new_row)\n",
        "\n",
        "df_chunked = pd.DataFrame(new_rows)\n",
        "\n",
        "print(\"Original rows:\", len(df))\n",
        "print(\"New rows after chunking:\", len(df_chunked))\n",
        "\n",
        "df_chunked.to_csv(\n",
        "    \"Datasets/BIGOIL_Chuncked_Dataset.csv\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "print(\"âœ… Saved: BIGOIL_pages_sentence_chunked.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82ARXAEIKbwP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Done. 7224 rows retained.\n",
            "âœ… Saved: BIGOIL_Cleaned_Dataset.csv Rows: 7224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/_r/x1wl6kys6bbcy57xk9d0db3w0000gn/T/ipykernel_88720/1007914732.py:60: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_filtered[\"Word_Count\"] = df_filtered[\"Text\"].str.split().str.len()\n",
            "/var/folders/_r/x1wl6kys6bbcy57xk9d0db3w0000gn/T/ipykernel_88720/1007914732.py:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_filtered[\"Char_Count\"] = df_filtered[\"Text\"].str.len()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Year</th>\n",
              "      <th>Page</th>\n",
              "      <th>Text</th>\n",
              "      <th>Char_Count</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Is_Sparse</th>\n",
              "      <th>Subpage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SHELL</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>responsible energy #poweringprogress shell plc...</td>\n",
              "      <td>73</td>\n",
              "      <td>8</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SHELL</td>\n",
              "      <td>2022</td>\n",
              "      <td>2</td>\n",
              "      <td>contents read the shell sustainability report ...</td>\n",
              "      <td>1790</td>\n",
              "      <td>270</td>\n",
              "      <td>False</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SHELL</td>\n",
              "      <td>2022</td>\n",
              "      <td>3</td>\n",
              "      <td>sustainability at shell welcome to the shell s...</td>\n",
              "      <td>510</td>\n",
              "      <td>76</td>\n",
              "      <td>False</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SHELL</td>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>letter from the ceo wael sawan chief executive...</td>\n",
              "      <td>2422</td>\n",
              "      <td>396</td>\n",
              "      <td>False</td>\n",
              "      <td>4.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SHELL</td>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>we joined two major projects in qatar, for exa...</td>\n",
              "      <td>1757</td>\n",
              "      <td>280</td>\n",
              "      <td>False</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9033</th>\n",
              "      <td>BP</td>\n",
              "      <td>2019</td>\n",
              "      <td>79</td>\n",
              "      <td>we have applied the international standard on ...</td>\n",
              "      <td>2240</td>\n",
              "      <td>324</td>\n",
              "      <td>False</td>\n",
              "      <td>79.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9034</th>\n",
              "      <td>BP</td>\n",
              "      <td>2019</td>\n",
              "      <td>80</td>\n",
              "      <td>generation and storage; creating a diverse and...</td>\n",
              "      <td>2428</td>\n",
              "      <td>391</td>\n",
              "      <td>False</td>\n",
              "      <td>80.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9035</th>\n",
              "      <td>BP</td>\n",
              "      <td>2019</td>\n",
              "      <td>80</td>\n",
              "      <td>these statements may generally, but not always...</td>\n",
              "      <td>2297</td>\n",
              "      <td>354</td>\n",
              "      <td>False</td>\n",
              "      <td>80.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9036</th>\n",
              "      <td>BP</td>\n",
              "      <td>2019</td>\n",
              "      <td>81</td>\n",
              "      <td>about this report order copies bpâ€™s printed pu...</td>\n",
              "      <td>814</td>\n",
              "      <td>110</td>\n",
              "      <td>False</td>\n",
              "      <td>81.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9037</th>\n",
              "      <td>BP</td>\n",
              "      <td>2019</td>\n",
              "      <td>82</td>\n",
              "      <td>bp p.l.c. 1 st jamesâ€™s square london sw1y 4pd ...</td>\n",
              "      <td>84</td>\n",
              "      <td>14</td>\n",
              "      <td>False</td>\n",
              "      <td>82.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7224 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Company  Year  Page                                               Text  \\\n",
              "0      SHELL  2022     1  responsible energy #poweringprogress shell plc...   \n",
              "1      SHELL  2022     2  contents read the shell sustainability report ...   \n",
              "2      SHELL  2022     3  sustainability at shell welcome to the shell s...   \n",
              "3      SHELL  2022     4  letter from the ceo wael sawan chief executive...   \n",
              "4      SHELL  2022     4  we joined two major projects in qatar, for exa...   \n",
              "...      ...   ...   ...                                                ...   \n",
              "9033      BP  2019    79  we have applied the international standard on ...   \n",
              "9034      BP  2019    80  generation and storage; creating a diverse and...   \n",
              "9035      BP  2019    80  these statements may generally, but not always...   \n",
              "9036      BP  2019    81  about this report order copies bpâ€™s printed pu...   \n",
              "9037      BP  2019    82  bp p.l.c. 1 st jamesâ€™s square london sw1y 4pd ...   \n",
              "\n",
              "      Char_Count  Word_Count  Is_Sparse  Subpage  \n",
              "0             73           8      False      1.0  \n",
              "1           1790         270      False      2.0  \n",
              "2            510          76      False      3.0  \n",
              "3           2422         396      False      4.1  \n",
              "4           1757         280      False      4.2  \n",
              "...          ...         ...        ...      ...  \n",
              "9033        2240         324      False     79.3  \n",
              "9034        2428         391      False     80.1  \n",
              "9035        2297         354      False     80.2  \n",
              "9036         814         110      False     81.0  \n",
              "9037          84          14      False     82.0  \n",
              "\n",
              "[7224 rows x 8 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filtering and clearing\n",
        "# 1. Load CHUNKED dataset (important)\n",
        "df = pd.read_csv(\"Datasets/BIGOIL_Chuncked_Dataset.csv\")\n",
        "\n",
        "# 3. Light cleaning\n",
        "def light_clean(text):\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', str(text))\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = text.replace('-', ' ')\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip().lower()\n",
        "\n",
        "df[\"Text\"] = df[\"Text\"].apply(light_clean)\n",
        "\n",
        "# 4. Green / environmental lexicon\n",
        "greenwashing_keywords = [\n",
        "    \"environment\", \"environmental\", \"biodiversity\", \"nature\", \"ecosystem\", \"ecosystems\",\n",
        "    \"species\", \"ocean\", \"oceans\", \"forest\", \"forests\", \"water\", \"deforest\", \"deforestation\",\n",
        "    \"endangered\", \"protect\", \"protection\", \"agriculture\", \"agricultural\", \"continent\",\n",
        "    \"hemisphere\", \"climate\", \"climatic\", \"warming\", \"global warming\", \"extreme weather\",\n",
        "    \"cyclone\", \"cyclones\", \"biology\", \"biologist\", \"chemistry\", \"chemical\", \"chemicals\",\n",
        "    \"sustainable\", \"sustainability\", \"sustain\", \"green\", \"greenwashing\", \"greenhouse\",\n",
        "    \"renewable\", \"renewables\", \"energy\", \"clean energy\", \"net zero\", \"carbon neutrality\",\n",
        "    \"carbon neutral\", \"transition\", \"transitions\", \"transitioning\", \"decarbon\",\n",
        "    \"decarbonize\", \"decarbonise\", \"decarbonization\", \"decarbonisation\",\n",
        "    \"alternative energy\", \"alternative fuel\", \"green investment\", \"green investments\",\n",
        "    \"circular economy\", \"low carbon\", \"climate positive\", \"energy efficiency\",\n",
        "    \"energy efficient\", \"dual challenge\", \"ambition\", \"ambitions\", \"commitment\",\n",
        "    \"commitments\", \"leadership\", \"vision\", \"visionary\", \"carbon\", \"carbon dioxide\", \"co2\",\n",
        "    \"ghg\", \"greenhouse gas\", \"greenhouse gases\", \"emission\", \"emissions\", \"methane\", \"ch4\",\n",
        "    \"footprint\", \"carbon footprint\", \"effluent\", \"effluents\", \"pollutant\", \"pollutants\",\n",
        "    \"pollution\", \"hazardous\", \"hazard\", \"contaminated\", \"contamination\", \"disposal\",\n",
        "    \"waste disposal\", \"flaring\", \"gas flaring\", \"abatement\", \"carbon abatement\",\n",
        "    \"carbon capture\", \"carbon sink\", \"carbon offset\", \"carbon offsets\", \"carbon tax\",\n",
        "    \"carbon pricing\", \"carbon price\", \"solar\", \"solar power\", \"solar energy\", \"wind\",\n",
        "    \"wind energy\", \"wind power\", \"hydrogen\", \"green hydrogen\", \"biofuel\", \"biofuels\",\n",
        "    \"biomass\", \"battery\", \"batteries\", \"geothermal\", \"electric vehicle\",\n",
        "    \"electric vehicles\", \"ev\", \"evs\", \"hydropower\", \"hydroelectric\", \"clean tech\",\n",
        "    \"material\", \"materials\", \"metric\", \"metrics\", \"target\", \"targets\", \"tonnes\", \"tons\",\n",
        "    \"scope 1\", \"scope 2\", \"scope 3\", \"baseline\", \"benchmark\", \"benchmarks\", \"reduction\",\n",
        "    \"reductions\", \"increase\", \"increases\", \"ogci\", \"ipcc\", \"paris agreement\", \"paris\",\n",
        "    \"kyoto\", \"unfccc\", \"1.5Â°c\", \"2Â°c\", \"two degrees\", \"one point five degrees\"\n",
        "]\n",
        "\n",
        "# 5. Regex pattern\n",
        "pattern = re.compile(\n",
        "    r'\\b(?:' + '|'.join(re.escape(word) for word in greenwashing_keywords) + r')\\b',\n",
        "    flags=re.IGNORECASE\n",
        ")\n",
        "\n",
        "# 6. Filter rows\n",
        "df_filtered = df[df[\"Text\"].apply(lambda x: bool(pattern.search(x)))]\n",
        "\n",
        "# 7. Adding word counts and chr counts\n",
        "df_filtered[\"Word_Count\"] = df_filtered[\"Text\"].str.split().str.len()\n",
        "df_filtered[\"Char_Count\"] = df_filtered[\"Text\"].str.len()\n",
        "\n",
        "# 8. Save\n",
        "df_filtered.to_csv(\"Datasets/BIGOIL_Cleaned_Dataset.csv\", index=False)\n",
        "\n",
        "print(f\"âœ… Done. {len(df_filtered)} rows retained.\")\n",
        "print(\"âœ… Saved: BIGOIL_Cleaned_Dataset.csv\", \"Rows:\", len(df_filtered))\n",
        "df_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWPczIntKrSo"
      },
      "outputs": [],
      "source": [
        "# Adding the new character counts etc --> INTEGRATED ABOVE DW DELETE LATER \n",
        "\n",
        "df = pd.read_csv(\"Datasets/BIGOIL_Cleaned_Dataset.csv\")\n",
        "\n",
        "df[\"Word_Count\"] = df[\"Text\"].str.split().str.len()\n",
        "df[\"Char_Count\"] = df[\"Text\"].str.len()\n",
        "\n",
        "df.to_csv(\"/content/cleaned_oil_chunked_fixed.csv\", index=False)\n",
        "print(\"âœ… Saved: cleaned_oil_chunked_fixed.csv\", \"Rows:\", len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uyIP8lJJK0u_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Lemmatisation complete. Saved as BIGOIL_Lemmatised_Dataset.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Year</th>\n",
              "      <th>Page</th>\n",
              "      <th>Text</th>\n",
              "      <th>Char_Count</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Is_Sparse</th>\n",
              "      <th>Subpage</th>\n",
              "      <th>lemmatised_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SHELL</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>responsible energy #poweringprogress shell plc...</td>\n",
              "      <td>73</td>\n",
              "      <td>8</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>responsible energy poweringprogress shell plc ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SHELL</td>\n",
              "      <td>2022</td>\n",
              "      <td>2</td>\n",
              "      <td>contents read the shell sustainability report ...</td>\n",
              "      <td>1790</td>\n",
              "      <td>270</td>\n",
              "      <td>False</td>\n",
              "      <td>2.0</td>\n",
              "      <td>content read the shell sustainability report o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SHELL</td>\n",
              "      <td>2022</td>\n",
              "      <td>3</td>\n",
              "      <td>sustainability at shell welcome to the shell s...</td>\n",
              "      <td>510</td>\n",
              "      <td>76</td>\n",
              "      <td>False</td>\n",
              "      <td>3.0</td>\n",
              "      <td>sustainability at shell welcome to the shell s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SHELL</td>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>letter from the ceo wael sawan chief executive...</td>\n",
              "      <td>2422</td>\n",
              "      <td>396</td>\n",
              "      <td>False</td>\n",
              "      <td>4.1</td>\n",
              "      <td>letter from the ceo wael sawan chief executive...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SHELL</td>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>we joined two major projects in qatar, for exa...</td>\n",
              "      <td>1757</td>\n",
              "      <td>280</td>\n",
              "      <td>False</td>\n",
              "      <td>4.2</td>\n",
              "      <td>we join two major project in qatar for example...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7219</th>\n",
              "      <td>BP</td>\n",
              "      <td>2019</td>\n",
              "      <td>79</td>\n",
              "      <td>we have applied the international standard on ...</td>\n",
              "      <td>2240</td>\n",
              "      <td>324</td>\n",
              "      <td>False</td>\n",
              "      <td>79.3</td>\n",
              "      <td>we have apply the international standard on qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7220</th>\n",
              "      <td>BP</td>\n",
              "      <td>2019</td>\n",
              "      <td>80</td>\n",
              "      <td>generation and storage; creating a diverse and...</td>\n",
              "      <td>2428</td>\n",
              "      <td>391</td>\n",
              "      <td>False</td>\n",
              "      <td>80.1</td>\n",
              "      <td>generation and storage create a diverse and in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7221</th>\n",
              "      <td>BP</td>\n",
              "      <td>2019</td>\n",
              "      <td>80</td>\n",
              "      <td>these statements may generally, but not always...</td>\n",
              "      <td>2297</td>\n",
              "      <td>354</td>\n",
              "      <td>False</td>\n",
              "      <td>80.2</td>\n",
              "      <td>these statement may generally but not always b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7222</th>\n",
              "      <td>BP</td>\n",
              "      <td>2019</td>\n",
              "      <td>81</td>\n",
              "      <td>about this report order copies bpâ€™s printed pu...</td>\n",
              "      <td>814</td>\n",
              "      <td>110</td>\n",
              "      <td>False</td>\n",
              "      <td>81.0</td>\n",
              "      <td>about this report order copy bp â€™s print publi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7223</th>\n",
              "      <td>BP</td>\n",
              "      <td>2019</td>\n",
              "      <td>82</td>\n",
              "      <td>bp p.l.c. 1 st jamesâ€™s square london sw1y 4pd ...</td>\n",
              "      <td>84</td>\n",
              "      <td>14</td>\n",
              "      <td>False</td>\n",
              "      <td>82.0</td>\n",
              "      <td>bp p.l.c 1 st james â€™s square london sw1y 4pd ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7224 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Company  Year  Page                                               Text  \\\n",
              "0      SHELL  2022     1  responsible energy #poweringprogress shell plc...   \n",
              "1      SHELL  2022     2  contents read the shell sustainability report ...   \n",
              "2      SHELL  2022     3  sustainability at shell welcome to the shell s...   \n",
              "3      SHELL  2022     4  letter from the ceo wael sawan chief executive...   \n",
              "4      SHELL  2022     4  we joined two major projects in qatar, for exa...   \n",
              "...      ...   ...   ...                                                ...   \n",
              "7219      BP  2019    79  we have applied the international standard on ...   \n",
              "7220      BP  2019    80  generation and storage; creating a diverse and...   \n",
              "7221      BP  2019    80  these statements may generally, but not always...   \n",
              "7222      BP  2019    81  about this report order copies bpâ€™s printed pu...   \n",
              "7223      BP  2019    82  bp p.l.c. 1 st jamesâ€™s square london sw1y 4pd ...   \n",
              "\n",
              "      Char_Count  Word_Count  Is_Sparse  Subpage  \\\n",
              "0             73           8      False      1.0   \n",
              "1           1790         270      False      2.0   \n",
              "2            510          76      False      3.0   \n",
              "3           2422         396      False      4.1   \n",
              "4           1757         280      False      4.2   \n",
              "...          ...         ...        ...      ...   \n",
              "7219        2240         324      False     79.3   \n",
              "7220        2428         391      False     80.1   \n",
              "7221        2297         354      False     80.2   \n",
              "7222         814         110      False     81.0   \n",
              "7223          84          14      False     82.0   \n",
              "\n",
              "                                        lemmatised_text  \n",
              "0     responsible energy poweringprogress shell plc ...  \n",
              "1     content read the shell sustainability report o...  \n",
              "2     sustainability at shell welcome to the shell s...  \n",
              "3     letter from the ceo wael sawan chief executive...  \n",
              "4     we join two major project in qatar for example...  \n",
              "...                                                 ...  \n",
              "7219  we have apply the international standard on qu...  \n",
              "7220  generation and storage create a diverse and in...  \n",
              "7221  these statement may generally but not always b...  \n",
              "7222  about this report order copy bp â€™s print publi...  \n",
              "7223  bp p.l.c 1 st james â€™s square london sw1y 4pd ...  \n",
              "\n",
              "[7224 rows x 9 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Â lemmantion etc\n",
        "# 1. Load the CLEAN & CHUNKED dataset\n",
        "df = pd.read_csv(\"Datasets/BIGOIL_Cleaned_Dataset.csv\")\n",
        "\n",
        "# 2. Load spaCy with only what we need\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
        "\n",
        "# 3. Lemmatisation function\n",
        "def lemmatise_text(text):\n",
        "    doc = nlp(str(text))\n",
        "    lemmas = [\n",
        "        token.lemma_\n",
        "        for token in doc\n",
        "        if not token.is_punct and not token.is_space\n",
        "    ]\n",
        "    return \" \".join(lemmas)\n",
        "\n",
        "# 4. Apply lemmatization\n",
        "df[\"lemmatised_text\"] = df[\"Text\"].apply(lemmatise_text)\n",
        "\n",
        "# 5. Save output\n",
        "df.to_csv(\"Datasets/BIGOIL_Lemmatised_Dataset.csv\", index=False)\n",
        "\n",
        "print(\"âœ… Lemmatisation complete. Saved as BIGOIL_Lemmatised_Dataset.csv\")\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "70jjhz7tLHG5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use mps:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… RoBERTa sentiment complete!\n",
            "Saved as: Datasets/BIGOIL_Sentiment_Dataset.csv\n",
            "                                                Text sentiment_label  \\\n",
            "0  responsible energy #poweringprogress shell plc...        POSITIVE   \n",
            "1  contents read the shell sustainability report ...        POSITIVE   \n",
            "2  sustainability at shell welcome to the shell s...        POSITIVE   \n",
            "3  letter from the ceo wael sawan chief executive...        POSITIVE   \n",
            "4  we joined two major projects in qatar, for exa...        POSITIVE   \n",
            "\n",
            "   sentiment_score  \n",
            "0         0.998575  \n",
            "1         0.997634  \n",
            "2         0.998773  \n",
            "3         0.998425  \n",
            "4         0.998379  \n"
          ]
        }
      ],
      "source": [
        "# basic sentiment analysis\n",
        "\n",
        "# 1. Load your latest dataset\n",
        "df = pd.read_csv(\"Datasets/BIGOIL_Lemmatised_Dataset.csv\")\n",
        "\n",
        "# 2. Load RoBERTa-based sentiment model\n",
        "sentiment_model = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"siebert/sentiment-roberta-large-english\"\n",
        ")\n",
        "\n",
        "# 3. Sentiment function (safe truncation)\n",
        "def get_sentiment(text):\n",
        "    result = sentiment_model(\n",
        "        str(text),\n",
        "        truncation=True\n",
        "    )[0]\n",
        "    return result[\"label\"], float(result[\"score\"])\n",
        "\n",
        "# 4. Apply sentiment analysis\n",
        "df[[\"sentiment_label\", \"sentiment_score\"]] = df[\"Text\"].apply(\n",
        "    lambda x: pd.Series(get_sentiment(x))\n",
        ")\n",
        "\n",
        "# 5. Save output\n",
        "output_path = \"Datasets/BIGOIL_Sentiment_Dataset.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(\"âœ… RoBERTa sentiment complete!\")\n",
        "print(\"Saved as:\", output_path)\n",
        "\n",
        "# Quick sanity check\n",
        "print(df[[\"Text\", \"sentiment_label\", \"sentiment_score\"]].head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1yvYyPZLKhy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded dataset: (7224, 11)\n",
            "\n",
            "Running model: climatebert/distilroberta-base-climate-specificity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use mps:0\n",
            "/Users/rezafayaz/Documents/Dissertation MDS /Final Files/BigOilNLPAnalysis/.venv/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Finished: specificity\n",
            "\n",
            "Running model: climatebert/distilroberta-base-climate-detector\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use mps:0\n",
            "/Users/rezafayaz/Documents/Dissertation MDS /Final Files/BigOilNLPAnalysis/.venv/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Finished: climate_detector\n",
            "\n",
            "Running model: climatebert/distilroberta-base-climate-commitment\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use mps:0\n",
            "/Users/rezafayaz/Documents/Dissertation MDS /Final Files/BigOilNLPAnalysis/.venv/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Finished: commitment\n",
            "\n",
            "Running model: climatebert/distilroberta-base-climate-tcfd\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use mps:0\n",
            "/Users/rezafayaz/Documents/Dissertation MDS /Final Files/BigOilNLPAnalysis/.venv/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Finished: tcfd\n",
            "\n",
            "Running model: climatebert/distilroberta-base-climate-sentiment\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use mps:0\n",
            "/Users/rezafayaz/Documents/Dissertation MDS /Final Files/BigOilNLPAnalysis/.venv/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# ClimateBERT Full Inference Pipeline (ALL MODELS)\n",
        "# =====================================================\n",
        "\n",
        "# =====================================================\n",
        "# 3. Load dataset\n",
        "# =====================================================\n",
        "\n",
        "INPUT_PATH = \"Datasets/BIGOIL_Sentiment_Dataset.csv\"\n",
        "OUTPUT_PATH = \"Datasets/BIGOIL_Sentiment_ClimateBert_Dataset.csv\"\n",
        "\n",
        "df = pd.read_csv(INPUT_PATH)\n",
        "\n",
        "print(\"Loaded dataset:\", df.shape)\n",
        "\n",
        "# =====================================================\n",
        "# 4. Helper function to run any ClimateBERT classifier\n",
        "# =====================================================\n",
        "\n",
        "def run_climate_model(model_name, prefix, df, batch_size=16):\n",
        "    \"\"\"\n",
        "    Runs a HuggingFace text-classification model on df['Text']\n",
        "    and appends label, score, and full probability distribution.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nRunning model: {model_name}\")\n",
        "\n",
        "    clf = pipeline(\n",
        "        \"text-classification\",\n",
        "        model=model_name,\n",
        "        device=0,                 # GPU\n",
        "        truncation=True,\n",
        "        return_all_scores=True\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    scores = []\n",
        "    probs  = []\n",
        "\n",
        "    texts = df[\"Text\"].astype(str).tolist()\n",
        "\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        outputs = clf(batch)\n",
        "\n",
        "        for out in outputs:\n",
        "            # Sort predictions by confidence\n",
        "            out_sorted = sorted(out, key=lambda x: x[\"score\"], reverse=True)\n",
        "            best = out_sorted[0]\n",
        "\n",
        "            labels.append(best[\"label\"])\n",
        "            scores.append(float(best[\"score\"]))\n",
        "            probs.append({d[\"label\"]: float(d[\"score\"]) for d in out})\n",
        "\n",
        "    df[f\"{prefix}_label\"] = labels\n",
        "    df[f\"{prefix}_score\"] = scores\n",
        "    df[f\"{prefix}_probs\"] = probs\n",
        "\n",
        "    print(f\"âœ… Finished: {prefix}\")\n",
        "\n",
        "# =====================================================\n",
        "# 5. Run ALL ClimateBERT models\n",
        "# =====================================================\n",
        "\n",
        "# 5.1 Specificity (specific vs non-specific)\n",
        "run_climate_model(\n",
        "    model_name=\"climatebert/distilroberta-base-climate-specificity\",\n",
        "    prefix=\"specificity\",\n",
        "    df=df\n",
        ")\n",
        "\n",
        "# 5.2 Climate detector (climate vs not)\n",
        "run_climate_model(\n",
        "    model_name=\"climatebert/distilroberta-base-climate-detector\",\n",
        "    prefix=\"climate_detector\",\n",
        "    df=df\n",
        ")\n",
        "\n",
        "# 5.3 Commitment framing\n",
        "run_climate_model(\n",
        "    model_name=\"climatebert/distilroberta-base-climate-commitment\",\n",
        "    prefix=\"commitment\",\n",
        "    df=df\n",
        ")\n",
        "\n",
        "# 5.4 TCFD category classification\n",
        "run_climate_model(\n",
        "    model_name=\"climatebert/distilroberta-base-climate-tcfd\",\n",
        "    prefix=\"tcfd\",\n",
        "    df=df\n",
        ")\n",
        "\n",
        "# 5.5 Climate-specific sentiment\n",
        "run_climate_model(\n",
        "    model_name=\"climatebert/distilroberta-base-climate-sentiment\",\n",
        "    prefix=\"climate_sentiment\",\n",
        "    df=df\n",
        ")\n",
        "\n",
        "# =====================================================\n",
        "# 6. Save final dataset\n",
        "# =====================================================\n",
        "\n",
        "df.to_csv(OUTPUT_PATH, index=False)\n",
        "\n",
        "print(\"\\nðŸŽ‰ ALL CLIMATEBERT MODELS COMPLETED\")\n",
        "print(\"Saved to:\", OUTPUT_PATH)\n",
        "print(\"Final shape:\", df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1B3SfO0LNd3"
      },
      "outputs": [],
      "source": [
        "# addition of buzzword scoring and fuutre scoring\n",
        "\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/clean_fresh_oil_with_all_climatebert.csv')\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# --- POS-based future verbs (as lemmas) ---\n",
        "future_verbs = {\n",
        "    \"will\", \"shall\", \"aim\", \"aiming\", \"plan\", \"planning\", \"target\", \"aspire\",\n",
        "    \"commit\", \"committed\", \"pledge\", \"pledged\", \"pledging\", \"vow\", \"promise\",\n",
        "    \"seek\", \"intend\", \"intends\", \"hope\", \"envision\", \"anticipate\", \"anticipates\", \"forecast\",\n",
        "    \"forecasting\", \"project\", \"projects\", \"projected\", \"look\", \"working\", \"moving\", \"set\"\n",
        "}\n",
        "\n",
        "# --- Phrase-based future expressions (not captured as single tokens by spaCy) ---\n",
        "future_phrases = [\n",
        "    \"going to\", \"seek to\", \"intend to\", \"set out to\", \"hope to\", \"looking to\",\n",
        "    \"working to\", \"working towards\", \"moving towards\", \"transition plan\",\n",
        "    \"path to net zero\", \"by 2030\", \"by 2050\",\n",
        "    \"weâ€™re helping to save the planet\"\n",
        "]\n",
        "\n",
        "# --- Buzzword lexicon for greenwashing ---\n",
        "greenwashing_lexicon = [\n",
        "    \"green\", \"clean\", \"cleaner\", \"cleanest\", \"efficient\", \"sustainable\",\n",
        "    \"sustainability\", \"eco-friendly\", \"environmentally friendly\", \"earth-friendly\",\n",
        "    \"eco-conscious\", \"natural\", \"non-toxic\", \"organic\", \"ethical\", \"biodegradable\",\n",
        "    \"carbon neutral\", \"climate neutral\", \"carbon offsets\", \"carbon offset\", \"carbon credits\",\n",
        "    \"low carbon\", \"fuels of tomorrow\", \"resilient hydrocarbons\", \"energy in progress\",\n",
        "    \"transformation\", \"energy transition\", \"transition\", \"beyond petroleum\",\n",
        "    \"emissions intensity\", \"locally grown\", \"sustainably sourced\", \"eco-safe\",\n",
        "    \"eco-preferred\", \"cfc-free\", \"chlorofluorocarbon-free\", \"renewable natural gas\", \"rng\",\n",
        "    \"carbon capture and storage\", \"ccs\", \"e-fuels\", \"synthetic fuels\", \"synth-fuels\",\n",
        "    \"carbon-neutral e-fuels\", \"drive carbon neutral\"\n",
        "]\n",
        "\n",
        "# --- Compile regex patterns for phrase matching ---\n",
        "future_phrase_pattern = re.compile(r'\\b(?:' + '|'.join(re.escape(phrase) for phrase in future_phrases) + r')\\b', flags=re.IGNORECASE)\n",
        "buzzword_pattern = re.compile(r'\\b(?:' + '|'.join(re.escape(term) for term in greenwashing_lexicon) + r')\\b', flags=re.IGNORECASE)\n",
        "\n",
        "# --- POS-based future score function ---\n",
        "def pos_future_score(text):\n",
        "    if pd.isnull(text) or text.strip() == \"\":\n",
        "        return 0.0\n",
        "\n",
        "    doc = nlp(text)\n",
        "    token_count = len(doc)\n",
        "    future_count = 0\n",
        "\n",
        "    for i, token in enumerate(doc):\n",
        "        lemma = token.lemma_.lower()\n",
        "        pos = token.pos_\n",
        "\n",
        "        # Match modal verbs like \"will\", \"shall\" only when followed by a verb\n",
        "        if lemma in {\"will\", \"shall\"} and token.tag_ == \"MD\":\n",
        "            if i + 1 < token_count and doc[i + 1].pos_ == \"VERB\":\n",
        "                future_count += 1\n",
        "            else:\n",
        "                future_count += 1  # accept anyway to stay inclusive\n",
        "\n",
        "        # Match intention/commitment words when used as verbs or auxiliaries\n",
        "        elif lemma in future_verbs and pos in {\"VERB\", \"AUX\"}:\n",
        "            future_count += 1\n",
        "\n",
        "    # Also match multi-word future phrases via regex\n",
        "    future_count += len(future_phrase_pattern.findall(text.lower()))\n",
        "\n",
        "    return future_count / token_count if token_count > 0 else 0.0\n",
        "\n",
        "# --- Buzzword score function (greenwashing density) ---\n",
        "def buzzword_score(text):\n",
        "    if pd.isnull(text) or text.strip() == \"\":\n",
        "        return 0.0\n",
        "    word_count = len(text.split())\n",
        "    if word_count == 0:\n",
        "        return 0.0\n",
        "    buzzword_matches = buzzword_pattern.findall(text.lower())\n",
        "    return len(buzzword_matches) / word_count\n",
        "\n",
        "# --- Apply both scoring functions to your DataFrame ---\n",
        "df[\"future_score_pos\"] = df[\"Text\"].apply(pos_future_score)\n",
        "df[\"buzzword_score\"] = df[\"Text\"].apply(buzzword_score)\n",
        "\n",
        "# --- Save new dataset with both scores included ---\n",
        "df.to_csv(\"/content/oil_reports_with_future_and_buzzword_scores.csv\", index=False)\n",
        "\n",
        "print(\"âœ… POS-based future score and buzzword score added!\")\n",
        "print(\"ðŸ“„ Saved as: oil_reports_with_future_and_buzzword_scores.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
